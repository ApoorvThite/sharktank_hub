{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 3: DATA PREPROCESSING & FEATURE ENGINEERING\n",
    "## Shark Tank India - Creating 35+ Engineered Features\n",
    "\n",
    "**Objectives:**\n",
    "- Clean data for modeling\n",
    "- Create 35+ engineered features\n",
    "- Handle missing values strategically\n",
    "- Prepare train/test splits\n",
    "\n",
    "**Feature Categories:**\n",
    "1. Financial Health Indicators (10 features)\n",
    "2. Deal Structure Indicators (8 features)\n",
    "3. Team Composition Features (7 features)\n",
    "4. Innovation Indicators (4 features)\n",
    "5. Shark Affinity Scores (7 features)\n",
    "6. Industry Context Features (5 features)\n",
    "7. Geographic Features (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df = pd.read_csv('../data/raw/Shark Tank India.csv')\n",
    "\n",
    "print(f\"üìä Dataset loaded: {df.shape}\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "print(\"\\n‚úÖ Data loaded and copied for feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA CLEANING\n",
    "\n",
    "### 2.1 Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üßπ MISSING VALUE TREATMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Shark-specific columns - fill with 0 (means no investment)\n",
    "shark_names = ['Namita', 'Vineeta', 'Anupam', 'Aman', 'Peyush', 'Ritesh', 'Amit', 'Guest']\n",
    "shark_cols = []\n",
    "\n",
    "for shark in shark_names:\n",
    "    for suffix in ['Investment Amount', 'Investment Equity', 'Debt Amount']:\n",
    "        col = f'{shark} {suffix}'\n",
    "        if col in df_fe.columns:\n",
    "            df_fe[col] = df_fe[col].fillna(0)\n",
    "            shark_cols.append(col)\n",
    "\n",
    "print(f\"‚úÖ Filled {len(shark_cols)} shark-specific columns with 0\")\n",
    "\n",
    "# Financial metrics - industry median imputation\n",
    "financial_cols = ['Yearly Revenue', 'Monthly Sales', 'Gross Margin', 'Net Margin', 'EBITDA']\n",
    "for col in financial_cols:\n",
    "    if col in df_fe.columns:\n",
    "        df_fe[col] = df_fe.groupby('Industry')[col].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        print(f\"‚úÖ Imputed {col} with industry median\")\n",
    "\n",
    "# SKUs - fill with median\n",
    "if 'SKUs' in df_fe.columns:\n",
    "    df_fe['SKUs'] = df_fe['SKUs'].fillna(df_fe['SKUs'].median())\n",
    "    print(f\"‚úÖ Imputed SKUs with median\")\n",
    "\n",
    "# Deal-specific columns - fill with 0\n",
    "deal_cols = ['Total Deal Amount', 'Total Deal Equity', 'Total Deal Debt', 'Debt Interest',\n",
    "             'Royalty Percentage', 'Royalty Recouped Amount', 'Advisory Shares Equity']\n",
    "for col in deal_cols:\n",
    "    if col in df_fe.columns:\n",
    "        df_fe[col] = df_fe[col].fillna(0)\n",
    "\n",
    "print(f\"‚úÖ Filled {len([c for c in deal_cols if c in df_fe.columns])} deal columns with 0\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing value treatment completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üîÑ DATA TYPE CONVERSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert Yes/No to 1/0\n",
    "binary_cols = ['Cash Burn', 'Has Patents', 'Bootstrapped']\n",
    "for col in binary_cols:\n",
    "    if col in df_fe.columns:\n",
    "        df_fe[col] = df_fe[col].map({'Yes': 1, 'yes': 1, 'No': 0, 'no': 0}).fillna(0)\n",
    "        print(f\"‚úÖ Converted {col} to binary (1/0)\")\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_cols = ['Yearly Revenue', 'Monthly Sales', 'Gross Margin', 'Net Margin',\n",
    "                'Original Ask Amount', 'Original Offered Equity', 'Valuation Requested']\n",
    "for col in numeric_cols:\n",
    "    if col in df_fe.columns:\n",
    "        df_fe[col] = pd.to_numeric(df_fe[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(\"\\n‚úÖ Data type conversions completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Outlier Detection (Flag, Don't Remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üîç OUTLIER DETECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Flag high valuation outliers\n",
    "if 'Valuation Requested' in df_fe.columns:\n",
    "    Q1 = df_fe['Valuation Requested'].quantile(0.25)\n",
    "    Q3 = df_fe['Valuation Requested'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_fe['is_outlier_valuation'] = (df_fe['Valuation Requested'] > upper_bound).astype(int)\n",
    "    print(f\"‚úÖ Created is_outlier_valuation: {df_fe['is_outlier_valuation'].sum()} outliers flagged\")\n",
    "\n",
    "# Flag high revenue\n",
    "if 'Yearly Revenue' in df_fe.columns:\n",
    "    df_fe['is_high_revenue'] = (df_fe['Yearly Revenue'] > 1000).astype(int)\n",
    "    print(f\"‚úÖ Created is_high_revenue: {df_fe['is_high_revenue'].sum()} high revenue startups\")\n",
    "\n",
    "print(\"\\n‚úÖ Outlier detection completed (flagged, not removed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FEATURE ENGINEERING - 35+ NEW FEATURES\n",
    "\n",
    "### 3.1 Financial Health Indicators (10 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üí∞ FINANCIAL HEALTH INDICATORS (10 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. Revenue per SKU\n",
    "df_fe['revenue_per_sku'] = df_fe['Yearly Revenue'] / (df_fe['SKUs'] + 1)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. revenue_per_sku created\")\n",
    "\n",
    "# 2. Monthly to yearly ratio\n",
    "df_fe['monthly_to_yearly_ratio'] = (df_fe['Monthly Sales'] * 12) / (df_fe['Yearly Revenue'] + 1)\n",
    "df_fe['monthly_to_yearly_ratio'] = df_fe['monthly_to_yearly_ratio'].clip(0, 10)  # Cap at 10\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. monthly_to_yearly_ratio created\")\n",
    "\n",
    "# 3. Profit margin gap\n",
    "df_fe['profit_margin_gap'] = df_fe['Gross Margin'] - df_fe['Net Margin']\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. profit_margin_gap created\")\n",
    "\n",
    "# 4. Profitability score\n",
    "df_fe['profitability_score'] = (df_fe['Net Margin'] * df_fe['Yearly Revenue']) / 1000\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. profitability_score created\")\n",
    "\n",
    "# 5. EBITDA margin\n",
    "df_fe['ebitda_margin'] = df_fe['EBITDA'] / (df_fe['Yearly Revenue'] + 1)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. ebitda_margin created\")\n",
    "\n",
    "# 6. Burn rate\n",
    "df_fe['burn_rate'] = df_fe['Cash Burn'] * df_fe['Monthly Sales']\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. burn_rate created\")\n",
    "\n",
    "# 7. Runway months\n",
    "df_fe['runway_months'] = df_fe['Yearly Revenue'] / (df_fe['burn_rate'] + 1)\n",
    "df_fe['runway_months'] = df_fe['runway_months'].clip(0, 100)  # Cap at 100 months\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. runway_months created\")\n",
    "\n",
    "# 8. Is pre-revenue\n",
    "df_fe['is_pre_revenue'] = (df_fe['Yearly Revenue'] == 0).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_pre_revenue created\")\n",
    "\n",
    "# 9. Revenue category (ordinal)\n",
    "df_fe['revenue_category'] = pd.cut(df_fe['Yearly Revenue'], \n",
    "                                    bins=[-np.inf, 0, 100, 1000, 10000, np.inf],\n",
    "                                    labels=[0, 1, 2, 3, 4])\n",
    "df_fe['revenue_category'] = df_fe['revenue_category'].astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. revenue_category created (ordinal 0-4)\")\n",
    "\n",
    "# 10. Financial health score (composite)\n",
    "df_fe['financial_health_score'] = (\n",
    "    (df_fe['Yearly Revenue'] > 0).astype(int) * 2 +\n",
    "    (df_fe['Net Margin'] > 10).astype(int) * 2 +\n",
    "    (df_fe['Cash Burn'] == 0).astype(int) * 1\n",
    ")\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. financial_health_score created (0-5 scale)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Financial Health Indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Deal Structure Indicators (8 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ü§ù DEAL STRUCTURE INDICATORS (8 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. Revenue multiple\n",
    "df_fe['revenue_multiple'] = df_fe['Valuation Requested'] / (df_fe['Yearly Revenue'] + 1)\n",
    "df_fe['revenue_multiple'] = df_fe['revenue_multiple'].clip(0, 1000)  # Cap at 1000x\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. revenue_multiple created\")\n",
    "\n",
    "# 2. Ask percentage\n",
    "df_fe['ask_percentage'] = (df_fe['Original Ask Amount'] / (df_fe['Valuation Requested'] + 1)) * 100\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. ask_percentage created\")\n",
    "\n",
    "# 3. Valuation reasonableness (vs industry median)\n",
    "industry_median_multiple = df_fe.groupby('Industry')['revenue_multiple'].transform('median')\n",
    "df_fe['valuation_reasonableness'] = df_fe['revenue_multiple'] / (industry_median_multiple + 1)\n",
    "df_fe['valuation_reasonableness'] = df_fe['valuation_reasonableness'].clip(0, 10)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. valuation_reasonableness created\")\n",
    "\n",
    "# 4. Expected equity dilution\n",
    "df_fe['expected_equity_dilution'] = df_fe['Original Offered Equity']\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. expected_equity_dilution created\")\n",
    "\n",
    "# 5. Deal size category\n",
    "df_fe['deal_size_category'] = pd.cut(df_fe['Original Ask Amount'],\n",
    "                                      bins=[-np.inf, 50, 100, 200, 500, np.inf],\n",
    "                                      labels=[0, 1, 2, 3, 4])\n",
    "df_fe['deal_size_category'] = df_fe['deal_size_category'].astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. deal_size_category created (ordinal 0-4)\")\n",
    "\n",
    "# 6. Valuation to ask ratio\n",
    "df_fe['valuation_to_ask_ratio'] = df_fe['Valuation Requested'] / (df_fe['Original Ask Amount'] + 1)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. valuation_to_ask_ratio created\")\n",
    "\n",
    "# 7. Is reasonable valuation (within 2x of industry median)\n",
    "df_fe['is_reasonable_valuation'] = (df_fe['valuation_reasonableness'] <= 2).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_reasonable_valuation created\")\n",
    "\n",
    "# 8. Deal complexity score\n",
    "df_fe['deal_complexity_score'] = (\n",
    "    (df_fe['Total Deal Debt'] > 0).astype(int) +\n",
    "    (df_fe['Royalty Percentage'] > 0).astype(int) +\n",
    "    (df_fe['Advisory Shares Equity'] > 0).astype(int)\n",
    ")\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. deal_complexity_score created (0-3 scale)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Deal Structure Indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Team Composition Features (7 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üë• TEAM COMPOSITION FEATURES (7 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. Team size\n",
    "df_fe['team_size'] = df_fe['Number of Presenters'].fillna(1)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. team_size created\")\n",
    "\n",
    "# 2. Male ratio\n",
    "df_fe['male_ratio'] = df_fe['Male Presenters'] / (df_fe['team_size'] + 0.001)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. male_ratio created\")\n",
    "\n",
    "# 3. Female ratio\n",
    "df_fe['female_ratio'] = df_fe['Female Presenters'] / (df_fe['team_size'] + 0.001)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. female_ratio created\")\n",
    "\n",
    "# 4. Gender diversity score\n",
    "df_fe['gender_diversity_score'] = 1 - abs(df_fe['male_ratio'] - df_fe['female_ratio'])\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. gender_diversity_score created (0-1 scale)\")\n",
    "\n",
    "# 5. Is solo founder\n",
    "df_fe['is_solo_founder'] = (df_fe['team_size'] == 1).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_solo_founder created\")\n",
    "\n",
    "# 6. Is couple\n",
    "df_fe['is_couple'] = df_fe['Couple Presenters'].fillna(0).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_couple created\")\n",
    "\n",
    "# 7. Has female founder\n",
    "df_fe['has_female_founder'] = (df_fe['Female Presenters'] > 0).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. has_female_founder created\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Team Composition Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Innovation Indicators (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üí° INNOVATION INDICATORS (4 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. Has patent\n",
    "df_fe['has_patent'] = df_fe['Has Patents'].fillna(0).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. has_patent created\")\n",
    "\n",
    "# 2. Is bootstrapped\n",
    "df_fe['is_bootstrapped'] = df_fe['Bootstrapped'].fillna(0).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_bootstrapped created\")\n",
    "\n",
    "# 3. SKU count\n",
    "df_fe['sku_count'] = df_fe['SKUs'].fillna(0)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. sku_count created\")\n",
    "\n",
    "# 4. Innovation score (composite)\n",
    "df_fe['innovation_score'] = df_fe['has_patent'] * 2 + df_fe['is_bootstrapped']\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. innovation_score created (0-3 scale)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Innovation Indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Shark Affinity Scores (7 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ü¶à SHARK AFFINITY SCORES (7 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# Calculate industry affinity for each shark\n",
    "shark_names = ['Namita', 'Aman', 'Anupam', 'Peyush', 'Vineeta', 'Ritesh', 'Amit']\n",
    "\n",
    "for shark in shark_names:\n",
    "    investment_col = f'{shark} Investment Amount'\n",
    "    \n",
    "    if investment_col in df_fe.columns:\n",
    "        # Calculate industry-wise investment rate for this shark\n",
    "        industry_investments = df_fe.groupby('Industry')[investment_col].apply(\n",
    "            lambda x: (x > 0).sum()\n",
    "        )\n",
    "        total_investments = (df_fe[investment_col] > 0).sum()\n",
    "        \n",
    "        if total_investments > 0:\n",
    "            affinity = industry_investments / total_investments\n",
    "        else:\n",
    "            affinity = industry_investments * 0  # All zeros\n",
    "        \n",
    "        # Map affinity to each row based on industry\n",
    "        df_fe[f'{shark.lower()}_industry_fit'] = df_fe['Industry'].map(affinity).fillna(0)\n",
    "        feature_count += 1\n",
    "        print(f\"{feature_count}. {shark.lower()}_industry_fit created\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Shark Affinity Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Industry Context Features (5 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üè≠ INDUSTRY CONTEXT FEATURES (5 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. Industry average success rate\n",
    "industry_success_rate = df_fe.groupby('Industry')['Received Offer'].mean()\n",
    "df_fe['industry_avg_success_rate'] = df_fe['Industry'].map(industry_success_rate)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. industry_avg_success_rate created\")\n",
    "\n",
    "# 2. Industry average equity\n",
    "industry_avg_equity = df_fe.groupby('Industry')['Total Deal Equity'].mean()\n",
    "df_fe['industry_avg_equity'] = df_fe['Industry'].map(industry_avg_equity)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. industry_avg_equity created\")\n",
    "\n",
    "# 3. Industry median valuation\n",
    "industry_median_val = df_fe.groupby('Industry')['Valuation Requested'].median()\n",
    "df_fe['industry_median_valuation'] = df_fe['Industry'].map(industry_median_val)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. industry_median_valuation created\")\n",
    "\n",
    "# 4. Industry pitch count\n",
    "industry_pitch_count = df_fe.groupby('Industry')['Startup Name'].transform('count')\n",
    "df_fe['industry_pitch_count'] = industry_pitch_count\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. industry_pitch_count created\")\n",
    "\n",
    "# 5. Industry competition index\n",
    "df_fe['industry_competition_index'] = df_fe['industry_pitch_count'] / len(df_fe)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. industry_competition_index created\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Industry Context Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Geographic Features (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üó∫Ô∏è  GEOGRAPHIC FEATURES (4 features)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_count = 0\n",
    "\n",
    "# 1. State success rate\n",
    "state_success = df_fe.groupby('Pitchers State')['Received Offer'].mean()\n",
    "df_fe['state_success_rate'] = df_fe['Pitchers State'].map(state_success)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. state_success_rate created\")\n",
    "\n",
    "# 2. Is metro\n",
    "metro_states = ['Maharashtra', 'Delhi', 'Karnataka']\n",
    "df_fe['is_metro'] = df_fe['Pitchers State'].isin(metro_states).astype(int)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. is_metro created\")\n",
    "\n",
    "# 3. State pitch density\n",
    "state_pitch_density = df_fe.groupby('Pitchers State')['Startup Name'].transform('count')\n",
    "df_fe['state_pitch_density'] = state_pitch_density\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. state_pitch_density created\")\n",
    "\n",
    "# 4. Geographic diversity score (normalized pitch density)\n",
    "df_fe['geographic_diversity_score'] = df_fe['state_pitch_density'] / len(df_fe)\n",
    "feature_count += 1\n",
    "print(f\"{feature_count}. geographic_diversity_score created\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {feature_count} Geographic Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FEATURE SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count engineered features\n",
    "original_cols = set(df.columns)\n",
    "new_cols = set(df_fe.columns) - original_cols\n",
    "engineered_features = sorted(list(new_cols))\n",
    "\n",
    "print(f\"\\n‚úÖ Total Engineered Features: {len(engineered_features)}\")\n",
    "print(f\"\\nFeature Categories:\")\n",
    "print(f\"   1. Financial Health Indicators: 10 features\")\n",
    "print(f\"   2. Deal Structure Indicators: 8 features\")\n",
    "print(f\"   3. Team Composition Features: 7 features\")\n",
    "print(f\"   4. Innovation Indicators: 4 features\")\n",
    "print(f\"   5. Shark Affinity Scores: 7 features\")\n",
    "print(f\"   6. Industry Context Features: 5 features\")\n",
    "print(f\"   7. Geographic Features: 4 features\")\n",
    "print(f\"   8. Outlier Flags: 2 features\")\n",
    "print(f\"   \" + \"-\"*50)\n",
    "print(f\"   TOTAL: {len(engineered_features)} features\")\n",
    "\n",
    "print(f\"\\nüìã All Engineered Features:\")\n",
    "for i, feat in enumerate(engineered_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset Shape After Feature Engineering:\")\n",
    "print(f\"   Rows: {len(df_fe):,}\")\n",
    "print(f\"   Columns: {len(df_fe.columns)} (original: {len(df.columns)}, new: {len(engineered_features)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TARGET VARIABLE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ TARGET VARIABLE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Binary classification targets\n",
    "df_fe['got_offer'] = df_fe['Received Offer'].astype(int)\n",
    "df_fe['accepted_offer'] = df_fe['Accepted Offer'].astype(int)\n",
    "\n",
    "print(f\"‚úÖ Binary targets created:\")\n",
    "print(f\"   - got_offer: {df_fe['got_offer'].sum()}/{len(df_fe)} ({df_fe['got_offer'].mean()*100:.1f}%)\")\n",
    "print(f\"   - accepted_offer: {df_fe['accepted_offer'].sum()}/{len(df_fe)} ({df_fe['accepted_offer'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Multi-label targets (7 sharks)\n",
    "shark_targets = []\n",
    "shark_names = ['Namita', 'Aman', 'Anupam', 'Peyush', 'Vineeta', 'Ritesh', 'Amit']\n",
    "\n",
    "print(f\"\\n‚úÖ Multi-label targets (individual sharks):\")\n",
    "for shark in shark_names:\n",
    "    investment_col = f'{shark} Investment Amount'\n",
    "    if investment_col in df_fe.columns:\n",
    "        target_col = f'{shark.lower()}_invested'\n",
    "        df_fe[target_col] = (df_fe[investment_col] > 0).astype(int)\n",
    "        shark_targets.append(target_col)\n",
    "        print(f\"   - {target_col}: {df_fe[target_col].sum()} deals ({df_fe[target_col].mean()*100:.1f}%)\")\n",
    "\n",
    "# Regression target\n",
    "df_fe['equity_dilution'] = df_fe['Total Deal Equity'] - df_fe['Original Offered Equity']\n",
    "print(f\"\\n‚úÖ Regression target created:\")\n",
    "print(f\"   - equity_dilution: Mean={df_fe['equity_dilution'].mean():.2f}%, Std={df_fe['equity_dilution'].std():.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total targets created: {2 + len(shark_targets) + 1} (2 binary + {len(shark_targets)} multi-label + 1 regression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. FEATURE SELECTION & CORRELATION ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üîç FEATURE SELECTION & CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select only numeric features for modeling\n",
    "numeric_features = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove target variables and identifiers from features\n",
    "exclude_cols = ['Season Number', 'Episode Number', 'Pitch Number', 'got_offer', 'accepted_offer', \n",
    "                'equity_dilution', 'Received Offer', 'Accepted Offer'] + shark_targets\n",
    "\n",
    "# Also exclude individual shark investment amounts (we have affinity scores instead)\n",
    "shark_investment_cols = [col for col in numeric_features if 'Investment Amount' in col or 'Investment Equity' in col or 'Debt Amount' in col]\n",
    "exclude_cols.extend(shark_investment_cols)\n",
    "\n",
    "feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
    "\n",
    "print(f\"\\nüìä Feature Selection:\")\n",
    "print(f\"   Total numeric columns: {len(numeric_features)}\")\n",
    "print(f\"   Excluded columns: {len(exclude_cols)}\")\n",
    "print(f\"   Selected features for modeling: {len(feature_cols)}\")\n",
    "\n",
    "# Correlation with target\n",
    "print(f\"\\nüéØ Top 20 Features Correlated with 'got_offer':\")\n",
    "correlations = df_fe[feature_cols + ['got_offer']].corr()['got_offer'].sort_values(ascending=False)\n",
    "top_20_corr = correlations[1:21]  # Exclude self-correlation\n",
    "\n",
    "for i, (feat, corr) in enumerate(top_20_corr.items(), 1):\n",
    "    print(f\"   {i:2d}. {feat:40s} : {corr:6.3f}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': correlations.index[1:],  # Exclude self\n",
    "    'Correlation_with_got_offer': correlations.values[1:]\n",
    "}).sort_values('Correlation_with_got_offer', ascending=False, key=abs)\n",
    "\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "feature_importance_df.to_csv('../data/processed/feature_importance_preliminary.csv', index=False)\n",
    "print(f\"\\n‚úÖ Saved: feature_importance_preliminary.csv\")\n",
    "\n",
    "# Check for highly correlated features (multicollinearity)\n",
    "print(f\"\\nüîç Checking for Multicollinearity (correlation > 0.95):\")\n",
    "corr_matrix = df_fe[feature_cols].corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr_pairs = [(column, row, corr_matrix.loc[row, column]) \n",
    "                   for column in upper_triangle.columns \n",
    "                   for row in upper_triangle.index \n",
    "                   if upper_triangle.loc[row, column] > 0.95]\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"   Found {len(high_corr_pairs)} highly correlated pairs:\")\n",
    "    for feat1, feat2, corr in high_corr_pairs[:10]:  # Show first 10\n",
    "        print(f\"   - {feat1} <-> {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(f\"   No highly correlated pairs found (good!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"‚úÇÔ∏è  TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare feature matrix\n",
    "X = df_fe[feature_cols].copy()\n",
    "y_binary = df_fe['got_offer'].copy()\n",
    "y_multilabel = df_fe[shark_targets].copy()\n",
    "y_regression = df_fe['equity_dilution'].copy()\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"\\nüìä Data Shapes:\")\n",
    "print(f\"   X (features): {X.shape}\")\n",
    "print(f\"   y_binary: {y_binary.shape}\")\n",
    "print(f\"   y_multilabel: {y_multilabel.shape}\")\n",
    "print(f\"   y_regression: {y_regression.shape}\")\n",
    "\n",
    "# Stratified split by industry to maintain distribution\n",
    "X_train, X_test, y_train_binary, y_test_binary = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=42, stratify=df_fe['Industry']\n",
    ")\n",
    "\n",
    "# Get corresponding indices for other targets\n",
    "train_idx = X_train.index\n",
    "test_idx = X_test.index\n",
    "\n",
    "y_train_multilabel = y_multilabel.loc[train_idx]\n",
    "y_test_multilabel = y_multilabel.loc[test_idx]\n",
    "\n",
    "y_train_regression = y_regression.loc[train_idx]\n",
    "y_test_regression = y_regression.loc[test_idx]\n",
    "\n",
    "print(f\"\\n‚úÖ Train/Test Split Complete:\")\n",
    "print(f\"   Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n   Binary target distribution:\")\n",
    "print(f\"   - Train: {y_train_binary.sum()}/{len(y_train_binary)} offers ({y_train_binary.mean()*100:.1f}%)\")\n",
    "print(f\"   - Test: {y_test_binary.sum()}/{len(y_test_binary)} offers ({y_test_binary.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SAVE PROCESSED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üíæ SAVING PROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save train/test splits\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "y_train_binary.to_csv('../data/processed/y_train_binary.csv', index=False, header=['got_offer'])\n",
    "y_test_binary.to_csv('../data/processed/y_test_binary.csv', index=False, header=['got_offer'])\n",
    "\n",
    "y_train_multilabel.to_csv('../data/processed/y_train_multilabel.csv', index=False)\n",
    "y_test_multilabel.to_csv('../data/processed/y_test_multilabel.csv', index=False)\n",
    "\n",
    "y_train_regression.to_csv('../data/processed/y_train_regression.csv', index=False, header=['equity_dilution'])\n",
    "y_test_regression.to_csv('../data/processed/y_test_regression.csv', index=False, header=['equity_dilution'])\n",
    "\n",
    "print(f\"‚úÖ Saved train/test splits:\")\n",
    "print(f\"   - X_train.csv ({X_train.shape})\")\n",
    "print(f\"   - X_test.csv ({X_test.shape})\")\n",
    "print(f\"   - y_train_binary.csv\")\n",
    "print(f\"   - y_test_binary.csv\")\n",
    "print(f\"   - y_train_multilabel.csv ({y_train_multilabel.shape})\")\n",
    "print(f\"   - y_test_multilabel.csv ({y_test_multilabel.shape})\")\n",
    "print(f\"   - y_train_regression.csv\")\n",
    "print(f\"   - y_test_regression.csv\")\n",
    "\n",
    "# Save full processed dataset\n",
    "df_fe.to_csv('../data/processed/processed_data_full.csv', index=False)\n",
    "print(f\"\\n‚úÖ Saved full processed dataset: processed_data_full.csv ({df_fe.shape})\")\n",
    "\n",
    "# Save feature list\n",
    "feature_list_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Data_Type': [df_fe[col].dtype for col in feature_cols]\n",
    "})\n",
    "feature_list_df.to_csv('../data/processed/feature_list.csv', index=False)\n",
    "print(f\"‚úÖ Saved feature list: feature_list.csv ({len(feature_cols)} features)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"üéâ PHASE 3 COMPLETE: DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚úÖ {len(engineered_features)} new features created\")\n",
    "print(f\"   ‚úÖ {len(feature_cols)} features selected for modeling\")\n",
    "print(f\"   ‚úÖ {len(X_train)} training samples, {len(X_test)} test samples\")\n",
    "print(f\"   ‚úÖ 3 target types: binary, multi-label (7 sharks), regression\")\n",
    "print(f\"   ‚úÖ All data saved to data/processed/\")\n",
    "print(f\"\\nüöÄ Ready for Phase 4: ML Model Training!\")\n",
    "print(f\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
